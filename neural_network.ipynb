{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "078bebea-eacd-009d-be23-ffd04a9a28d7"
   },
   "source": [
    "## Data exploration and feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5fd61b05-3123-f9f2-07b4-65f494b1d197"
   },
   "source": [
    "In this notebook I will explore the credit card transaction data downloaded from https://www.kaggle.com/mlg-ulb/creditcardfraud/data and use various techniques to select features for modeling. Feature selection reduces noise and allows the model to train on the most important information. Often time this helps improve the training speed as well as model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "fa5b0b2c-61af-c331-5189-ea7a7da91af4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "2fb18cab-d30f-a0b4-e2ac-965e8d54f46c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values.\n"
     ]
    }
   ],
   "source": [
    "if ~any(df.isnull().sum()):\n",
    "    print('No missing values.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "e0d66b9b-aa80-d98d-e0e4-2b6436ad643f",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.165980e-15</td>\n",
       "      <td>3.416908e-16</td>\n",
       "      <td>-1.373150e-15</td>\n",
       "      <td>2.086869e-15</td>\n",
       "      <td>9.604066e-16</td>\n",
       "      <td>1.490107e-15</td>\n",
       "      <td>-5.556467e-16</td>\n",
       "      <td>1.177556e-16</td>\n",
       "      <td>-2.406455e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.656562e-16</td>\n",
       "      <td>-3.444850e-16</td>\n",
       "      <td>2.578648e-16</td>\n",
       "      <td>4.471968e-15</td>\n",
       "      <td>5.340915e-16</td>\n",
       "      <td>1.687098e-15</td>\n",
       "      <td>-3.666453e-16</td>\n",
       "      <td>-1.220404e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.165980e-15  3.416908e-16 -1.373150e-15  2.086869e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   9.604066e-16  1.490107e-15 -5.556467e-16  1.177556e-16 -2.406455e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "           ...                 V21           V22           V23           V24  \\\n",
       "count      ...        2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...        1.656562e-16 -3.444850e-16  2.578648e-16  4.471968e-15   \n",
       "std        ...        7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min        ...       -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%        ...       -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%        ...       -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%        ...        1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max        ...        2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.340915e-16  1.687098e-15 -3.666453e-16 -1.220404e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5fd61b05-3123-f9f2-07b4-65f494b1d197"
   },
   "source": [
    "A few things to notice:\n",
    "1. There are 30 features: Time, Amount, and 28 others that are masked.\n",
    "2. The data is highly imbalanced: from the mean value of Class we see that only 0.17% of the transactions are fraud.\n",
    "3. The variances for V1 to V28 are already sorted. This suggests that V1-V28 have been already been PCA transformed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "array = df.values\n",
    "X = array[:,1:29]\n",
    "pca = PCA()\n",
    "X_new = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "3feb7a36-245c-d3c0-a85b-fb4a56b88602"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.72528658e-13,  7.87286902e-14, -2.88213897e-13, ...,\n",
       "         1.11577414e-14,  8.29891711e-15,  8.00817745e-14],\n",
       "       [-8.88178420e-16, -8.74855743e-14,  1.28147493e-13, ...,\n",
       "        -2.17326157e-14, -4.03271166e-14, -4.84855212e-15],\n",
       "       [ 1.33226763e-15, -8.88178420e-15,  7.79376563e-14, ...,\n",
       "         3.72479825e-14,  2.97747937e-14,  2.44179676e-14],\n",
       "       ...,\n",
       "       [ 0.00000000e+00,  1.12132525e-14, -7.99360578e-15, ...,\n",
       "         3.81639165e-15,  3.92047506e-16, -1.57859836e-15],\n",
       "       [ 1.41553436e-15,  3.66373598e-15, -4.32986980e-15, ...,\n",
       "         1.33226763e-15,  3.09474668e-15,  3.53883589e-15],\n",
       "       [ 1.22124533e-15, -8.32667268e-16,  3.21964677e-15, ...,\n",
       "        -1.44328993e-15,  3.73832909e-16, -4.57966998e-16]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(X_new)-abs(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5fd61b05-3123-f9f2-07b4-65f494b1d197"
   },
   "source": [
    "Applying Principal Component Analysis doesn't change the features except for some sign flips (due to the ambiguity in choosing a sign for the eigenvectors), so this does confirm that the given data has been PCA transformed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28']\n"
     ]
    }
   ],
   "source": [
    "n_PCA = 28 # number of features to keep after PCA\n",
    "features_PCA = ['V' + str(i) for i in range(1,n_PCA+1)]\n",
    "print(features_PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I will do supervised feature selection by choosing features that have the strongest correlation with the class. This can be done with the built-in SelectKBest function from scikit-learn. Here I use f_classif as score function (chi squared is for non-negative data). Optional: use ExtraTreesClassifier to fit the model to extract the importance of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V17', 'V14', 'V12', 'V10', 'V16', 'V3', 'V7', 'V11', 'V4', 'V18', 'V1', 'V9', 'V5', 'V2', 'V6']\n"
     ]
    }
   ],
   "source": [
    "X = array[:,1:29]\n",
    "y = array[:,30]\n",
    "select = SelectKBest(score_func=f_classif, k = 'all')\n",
    "fit = select.fit(X, y)\n",
    "scores_SKB = pd.DataFrame(fit.scores_)\n",
    "\n",
    "n_selectK = 15 # number of features to keep after SelectK\n",
    "features_selectK = ['V'+ str(i+1) for i in scores_SKB.nlargest(n_selectK,0).index]\n",
    "print(features_selectK)\n",
    "\n",
    "#model = ExtraTreesClassifier()\n",
    "#model.fit(X,y)\n",
    "#scores_ET = pd.DataFrame(model.feature_importances_)\n",
    "\n",
    "#n_ET = 15 # number of important features to keep after ExtraTrees\n",
    "#features_ET = ['v'+ str(i+1) for i in scores_ET.nlargest(n_ET,0).index]\n",
    "#print(features_ET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V11', 'V2', 'V7', 'V12', 'V4', 'V14', 'V1', 'V3', 'V5', 'V6', 'V9', 'V10', 'V17', 'V16', 'V18']\n"
     ]
    }
   ],
   "source": [
    "kept_features = list(set(features_selectK).intersection(features_PCA))\n",
    "print(kept_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dropped_features = ['V'+str(i) for i in range(1,29) if ('V'+str(i)) not in kept_features]\n",
    "#print(dropped_features)\n",
    "df = df.drop(dropped_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare training and testing data\n",
    "\n",
    "df.rename(columns={'Class':'Fraud'}, inplace=True)\n",
    "df['NonFraud'] = 1-df['Fraud']\n",
    "\n",
    "X = df.drop(['Fraud','NonFraud'],1)\n",
    "y = df[['Fraud','NonFraud']]\n",
    "\n",
    "# normalize the data to help the optimization\n",
    "for col in X.columns:\n",
    "    temp = X.loc[:,col]\n",
    "    mean, std = temp.mean(), temp.std()\n",
    "    X.loc[:,col] = (temp - mean) / std\n",
    "\n",
    "# shuffle and split data into training and testing sets\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=0)\n",
    "for idx_train, idx_test in sss.split(X, y):\n",
    "    X_train = X.iloc[idx_train]\n",
    "    y_train = y.iloc[idx_train]\n",
    "    X_test = X.iloc[idx_test]\n",
    "    y_test = y.iloc[idx_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "309dfd9b-b33a-60b3-c859-72eacc2bd323"
   },
   "source": [
    "## Train and test the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 200 # number of training epochs\n",
    "steps_to_check = 5\n",
    "\n",
    "batch_size = 1000\n",
    "learning_rate = 0.01\n",
    "keep_prob = 0.9 # for dropout method, to reduce overfitting\n",
    "\n",
    "n_nodes0 = len(kept_features) + 2 # number of input nodes\n",
    "n_nodes1 = 20 # number of nodes in the 1st hidden layer\n",
    "n_nodes2 = 25 # number of nodes in the 2nd hidden layer\n",
    "\n",
    "# set up the variables\n",
    "pkeep = tf.placeholder(tf.float32)\n",
    "x = tf.placeholder(tf.float32, [None, n_nodes0])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_nodes0, n_nodes1], stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([n_nodes1]))\n",
    "y1 = tf.nn.sigmoid(tf.matmul(x, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([n_nodes1, n_nodes2], stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([n_nodes2]))\n",
    "y2 = tf.nn.sigmoid(tf.matmul(y1, W2) + b2)\n",
    "y2 = tf.nn.dropout(y2, pkeep)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([n_nodes2, 2], stddev=0.1)) \n",
    "b3 = tf.Variable(tf.zeros([2]))\n",
    "y = tf.nn.softmax(tf.matmul(y2, W3) + b3)\n",
    "y_ = tf.placeholder(tf.float32, [None, 2])\n",
    "\n",
    "# use cross entropy as cost function\n",
    "cost_function = -tf.reduce_sum(y_*tf.log(y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost_function)\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    # initialize the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # train the network\n",
    "    for epoch in range(n_epochs): \n",
    "        for batch in range(int(len(X_train)/batch_size)):\n",
    "            X_batch = X_train[batch*batch_size:(1+batch)*batch_size]\n",
    "            y_batch = y_train[batch*batch_size:(1+batch)*batch_size]\n",
    "            sess.run([optimizer], {x: X_batch, y_: y_batch, pkeep: keep_prob})\n",
    "\n",
    "        # check cost and accuracy after fixed number of steps\n",
    "        if epoch % steps_to_check == 0:\n",
    "            acc, cost = sess.run([accuracy, cost_function], \n",
    "                                 {x: X_train, y_: y_train, pkeep: keep_prob})\n",
    "            print('Epoch: %4d    Cost: %8.2f    Accuracy: %.5f' %(epoch, cost, acc))\n",
    "    \n",
    "    print('\\nTraining completed.\\n')\n",
    "    print('Testing the model on test data.\\n')\n",
    "    \n",
    "    # test on test data\n",
    "    output = sess.run(y, {x: X_test, y_: y_test, pkeep:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = (y_test['Fraud'] > 0).astype(int)\n",
    "predict = (output[:,0] > output[:,1]).astype(int)\n",
    "from evaluation import confusion\n",
    "confusion(predict,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "13314f49-90f0-6fe2-f79b-c568672703c0"
   },
   "source": [
    "There are a lot of parameters to tune in order to optimize the performance of the model (size of the neural networks, number of training epochs, number of important features to keep etc.). Generally the accuracy is above 99.92%. The recall and precision for the positive class (fraud) can be around 80%, and those for the negative class (non-fraud) is above 99.96%."
   ]
  }
 ],
 "metadata": {
  "_change_revision": 44,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
